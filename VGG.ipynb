{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf92dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "from torch.hub import load_state_dict_from_url\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732fee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_type={\n",
    "    'A':[32,    'M',64,      'M',128,128,      'M',256,256,         'M',256,256,         'M'],\n",
    "    'B':[64,    'M',128,     'M',256,256,      'M',512,512,         'M',512,512,         'M'],\n",
    "    'C':[64,64, 'M',128,128, 'M',256,256,      'M',512,512,         'M',512,512,         'M'],\n",
    "    'D':[64,64, 'M',128,128, 'M',256,256,      'M',512,512,512,     'M',512,512,512,     'M'],\n",
    "    'E':[64,64, 'M',128,128, 'M',256,256,256,  'M',512,512,512,512, 'M',512,512,512,512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a7aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self,features,num_classes=10,init_weight=False):\n",
    "        super(VGG,self).__init__()\n",
    "        \n",
    "        self.features=features\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((7,7))\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Linear(256*7*7,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.classifier(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f196072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg11(pretrained=False,progress=True,**kwargs):\n",
    "    return _vgg('vgg11','A',pretrained,progress,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a972ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _vgg(arch,vgg_type_name,pretrained,progress,**kwargs):\n",
    "    if pretrained:\n",
    "        kwargs['init_weight']=False\n",
    "    model=VGG(make_layers(vgg_type[vgg_type_name]),**kwargs)\n",
    "    \n",
    "    if pretrained:\n",
    "        state_dict=load_state_dict_from_url(model_urls[arch],progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd71f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(vgg_arch):\n",
    "    layers=[]\n",
    "    in_channels=1\n",
    "    for i in vgg_arch:\n",
    "        if i=='M':\n",
    "            layers+=[nn.MaxPool2d(kernel_size=2,stride=2)]\n",
    "        else:\n",
    "            conv2d=nn.Conv2d(in_channels,i,kernel_size=3,padding=1)\n",
    "            layers+=[conv2d,nn.ReLU(inplace=True)]\n",
    "            in_channels=i\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75dbf84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2bf4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_config=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d297b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=datasets.FashionMNIST('/home/ubuntu/gpu_work',download=True,train=True,transform=transform_config)\n",
    "test_dataset=datasets.FashionMNIST('/home/ubuntu/gpu_work',download=True,train=False,transform=transform_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26bdb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "033f0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=vgg11().to(device)\n",
    "optimizer=optim.Adam(params=model.parameters(),lr=0.0001)\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96d49693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer,epoch,device):\n",
    "    model.train\n",
    "    for batch_ids, (data,label) in enumerate(train_loader):\n",
    "        label=label.type(torch.LongTensor)\n",
    "        data,label=data.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model_output=model(data)\n",
    "        loss=loss_fn(model_output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_ids+1)%50 == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch,batch_ids*len(data),len(train_loader.dataset),\n",
    "                100.*batch_ids/len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c16ba8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader,device):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for data,label in test_loader:\n",
    "            data,label=data.to(device),label.to(device)\n",
    "            y_hat=model(data)\n",
    "            _,y_pred=torch.max(y_hat,1)\n",
    "            correct+=(y_pred==label).sum().item()\n",
    "            test_loss+=F.nll_loss(y_hat,label,reduction='sum').item()\n",
    "        test_loss/=len(test_dataset)\n",
    "        print(\"\\n Test Set: Average loss: {:.0f}, Accuracy:{}/{} ({:.0f}%)\".format(\n",
    "            test_loss,correct,len(test_dataset),100.*correct/len(test_dataset)))\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "469a1e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12544/60000 (21%)]\tLoss: 0.407070\n",
      "Train Epoch: 1 [25344/60000 (42%)]\tLoss: 0.321637\n",
      "Train Epoch: 1 [38144/60000 (63%)]\tLoss: 0.346020\n",
      "Train Epoch: 1 [50944/60000 (85%)]\tLoss: 0.305505\n",
      "\n",
      " Test Set: Average loss: -8, Accuracy:8825/10000 (88%)\n",
      "==================================================\n",
      "Train Epoch: 2 [12544/60000 (21%)]\tLoss: 0.343530\n",
      "Train Epoch: 2 [25344/60000 (42%)]\tLoss: 0.327699\n",
      "Train Epoch: 2 [38144/60000 (63%)]\tLoss: 0.164542\n",
      "Train Epoch: 2 [50944/60000 (85%)]\tLoss: 0.316145\n",
      "\n",
      " Test Set: Average loss: -11, Accuracy:8966/10000 (90%)\n",
      "==================================================\n",
      "Train Epoch: 3 [12544/60000 (21%)]\tLoss: 0.148816\n",
      "Train Epoch: 3 [25344/60000 (42%)]\tLoss: 0.177497\n",
      "Train Epoch: 3 [38144/60000 (63%)]\tLoss: 0.221668\n",
      "Train Epoch: 3 [50944/60000 (85%)]\tLoss: 0.202405\n",
      "\n",
      " Test Set: Average loss: -10, Accuracy:9003/10000 (90%)\n",
      "==================================================\n",
      "Train Epoch: 4 [12544/60000 (21%)]\tLoss: 0.240699\n",
      "Train Epoch: 4 [25344/60000 (42%)]\tLoss: 0.196230\n",
      "Train Epoch: 4 [38144/60000 (63%)]\tLoss: 0.154728\n",
      "Train Epoch: 4 [50944/60000 (85%)]\tLoss: 0.170593\n",
      "\n",
      " Test Set: Average loss: -11, Accuracy:9113/10000 (91%)\n",
      "==================================================\n",
      "Train Epoch: 5 [12544/60000 (21%)]\tLoss: 0.132728\n",
      "Train Epoch: 5 [25344/60000 (42%)]\tLoss: 0.134112\n",
      "Train Epoch: 5 [38144/60000 (63%)]\tLoss: 0.198872\n",
      "Train Epoch: 5 [50944/60000 (85%)]\tLoss: 0.186907\n",
      "\n",
      " Test Set: Average loss: -13, Accuracy:9205/10000 (92%)\n",
      "==================================================\n",
      "Train Epoch: 6 [12544/60000 (21%)]\tLoss: 0.201291\n",
      "Train Epoch: 6 [25344/60000 (42%)]\tLoss: 0.167065\n",
      "Train Epoch: 6 [38144/60000 (63%)]\tLoss: 0.163135\n",
      "Train Epoch: 6 [50944/60000 (85%)]\tLoss: 0.201457\n",
      "\n",
      " Test Set: Average loss: -13, Accuracy:9147/10000 (91%)\n",
      "==================================================\n",
      "Train Epoch: 7 [12544/60000 (21%)]\tLoss: 0.119873\n",
      "Train Epoch: 7 [25344/60000 (42%)]\tLoss: 0.140351\n",
      "Train Epoch: 7 [38144/60000 (63%)]\tLoss: 0.100435\n",
      "Train Epoch: 7 [50944/60000 (85%)]\tLoss: 0.170885\n",
      "\n",
      " Test Set: Average loss: -14, Accuracy:9247/10000 (92%)\n",
      "==================================================\n",
      "Train Epoch: 8 [12544/60000 (21%)]\tLoss: 0.085889\n",
      "Train Epoch: 8 [25344/60000 (42%)]\tLoss: 0.093284\n",
      "Train Epoch: 8 [38144/60000 (63%)]\tLoss: 0.092750\n",
      "Train Epoch: 8 [50944/60000 (85%)]\tLoss: 0.102795\n",
      "\n",
      " Test Set: Average loss: -17, Accuracy:9256/10000 (93%)\n",
      "==================================================\n",
      "Train Epoch: 9 [12544/60000 (21%)]\tLoss: 0.115654\n",
      "Train Epoch: 9 [25344/60000 (42%)]\tLoss: 0.177368\n",
      "Train Epoch: 9 [38144/60000 (63%)]\tLoss: 0.096280\n",
      "Train Epoch: 9 [50944/60000 (85%)]\tLoss: 0.066570\n",
      "\n",
      " Test Set: Average loss: -19, Accuracy:9222/10000 (92%)\n",
      "==================================================\n",
      "Train Epoch: 10 [12544/60000 (21%)]\tLoss: 0.068032\n",
      "Train Epoch: 10 [25344/60000 (42%)]\tLoss: 0.039687\n",
      "Train Epoch: 10 [38144/60000 (63%)]\tLoss: 0.066661\n",
      "Train Epoch: 10 [50944/60000 (85%)]\tLoss: 0.105105\n",
      "\n",
      " Test Set: Average loss: -21, Accuracy:9279/10000 (93%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    seed=42\n",
    "    EPOCHS=10\n",
    "    \n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        train(model,train_loader,optimizer,epoch,device)\n",
    "        test(model,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "893e9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c402e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearn] *",
   "language": "python",
   "name": "conda-env-deeplearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
