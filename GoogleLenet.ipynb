{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c50f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "761cddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleLeNet(nn.Module):\n",
    "    def __init__(self,aux_logic=True,init_weight=True,num_classes=10):\n",
    "        super(GoogleLeNet,self).__init__()\n",
    "        \n",
    "        self.aux_logic=aux_logic\n",
    "        \n",
    "        if self.training:\n",
    "            print('self.training is True')\n",
    "        else:\n",
    "            print('self.training is False')\n",
    "            \n",
    "        self.conv1=BasicConv2d(1,64,kernel_size=7,stride=2,padding=3)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=3,stride=2,padding=0,ceil_mode=True)\n",
    "        self.conv2=BasicConv2d(64,64,kernel_size=1,stride=1,padding=0)\n",
    "        self.conv3=BasicConv2d(64,192,kernel_size=3,stride=1,padding=1)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=3,stride=2,padding=0,ceil_mode=True)\n",
    "        \n",
    "        self.inception3a=Inception_Block(192,64,96,128,16,32,32)\n",
    "        self.inception3b=Inception_Block(256,128,128,192,32,96,64)\n",
    "        self.maxpool3=nn.MaxPool2d(kernel_size=3,stride=2,ceil_mode=True)\n",
    "        \n",
    "        self.inception4a=Inception_Block(480,192,96,208,16,48,64)\n",
    "        self.inception4b=Inception_Block(512,160,112,224,24,64,64)\n",
    "        self.inception4c=Inception_Block(512,128,128,256,24,64,64)\n",
    "        self.inception4d=Inception_Block(512,112,144,288,32,64,64)\n",
    "        self.inception4e=Inception_Block(528,256,160,320,32,128,128)\n",
    "        self.maxpool4=nn.MaxPool2d(kernel_size=2,stride=2,ceil_mode=True)\n",
    "        \n",
    "        self.inception5a=Inception_Block(832,256,160,320,32,128,128)\n",
    "        self.inception5b=Inception_Block(832,384,192,384,48,128,128)\n",
    "        \n",
    "        if aux_logic:\n",
    "            self.aux1=Inception_Aux(512,num_classes)\n",
    "            self.aux2=Inception_Aux(528,num_classes)\n",
    "        \n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        self.fc=nn.Linear(1024,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.maxpool1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.maxpool2(x)\n",
    "        \n",
    "        x=self.inception3a(x)\n",
    "        x=self.inception3b(x)\n",
    "        x=self.maxpool3(x)\n",
    "        \n",
    "        x=self.inception4a(x)\n",
    "        \n",
    "        if self.aux_logic and self.training:\n",
    "            aux1=self.aux1(x)\n",
    "        \n",
    "        x=self.inception4b(x)\n",
    "        x=self.inception4c(x)\n",
    "        x=self.inception4d(x)\n",
    "        \n",
    "        if self.aux_logic and self.training:\n",
    "            aux2=self.aux2(x)\n",
    "            \n",
    "        x=self.inception4e(x)\n",
    "        x=self.maxpool4(x)\n",
    "        \n",
    "        x=self.inception5a(x)\n",
    "        x=self.inception5b(x)\n",
    "        \n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.dropout(x)\n",
    "        x=self.fc(x)\n",
    "        \n",
    "        if self.aux_logic and self.training:\n",
    "            return x,aux1,aux2\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a0aa985",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,**kwargs):\n",
    "        super(BasicConv2d,self).__init__()\n",
    "        \n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,**kwargs)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3a7329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Block(nn.Module):\n",
    "    def __init__(self,in_channels,out_1x1,red_3x3,out_3x3,red_5x5,out_5x5,out_1x1pool):\n",
    "        super(Inception_Block,self).__init__()\n",
    "        \n",
    "        self.branch1=BasicConv2d(in_channels,out_1x1,kernel_size=(1,1))\n",
    "        \n",
    "        self.branch2=nn.Sequential(\n",
    "            BasicConv2d(in_channels,red_3x3,kernel_size=(1,1)),\n",
    "            BasicConv2d(red_3x3,out_3x3,kernel_size=(3,3),padding=(1,1)),\n",
    "        )\n",
    "        \n",
    "        self.branch3=nn.Sequential(\n",
    "            BasicConv2d(in_channels,red_5x5,kernel_size=(1,1)),\n",
    "            BasicConv2d(red_5x5,out_5x5,kernel_size=(5,5),padding=(2,2))\n",
    "        )\n",
    "        \n",
    "        self.branch4=nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=(3,3),stride=(1,1),padding=(1,1),ceil_mode=True),\n",
    "            BasicConv2d(in_channels,out_1x1pool,kernel_size=(1,1))\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        branch1=self.branch1(x)\n",
    "        branch2=self.branch2(x)\n",
    "        branch3=self.branch3(x)\n",
    "        branch4=self.branch4(x)\n",
    "        output=[branch1,branch2,branch3,branch4]\n",
    "        return torch.cat(output,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8736076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_Aux(nn.Module):\n",
    "    def __init__(self,in_channels,num_classes):\n",
    "        super(Inception_Aux,self).__init__()\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout=nn.Dropout(p=0.7)\n",
    "        self.pool=nn.AvgPool2d(kernel_size=5,stride=3)\n",
    "        self.conv=BasicConv2d(in_channels,128,kernel_size=1)\n",
    "        self.fc1=nn.Linear(2048,1024)\n",
    "        self.fc2=nn.Linear(1024,num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.pool(x)\n",
    "        x=self.conv(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "820b5158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d677e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_config=transforms.Compose([\n",
    "    transforms.Resize((224,224)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b236e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256\n",
    "train_dataset=datasets.FashionMNIST('/home/ubuntu/gpu_work',download=True,train=True,transform=transform_config)\n",
    "test_dataset=datasets.FashionMNIST('/home/ubuntu/gpu_work',download=True,train=False,transform=transform_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01a30346",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89cee31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.training is True\n"
     ]
    }
   ],
   "source": [
    "model=GoogleLeNet().to(device)\n",
    "optimizer=optim.Adam(params=model.parameters(),lr=0.0001)\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38b2a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer,epoch,device):\n",
    "    model.train()\n",
    "    for batch_ids,(data,label) in enumerate(train_loader):\n",
    "        label=label.type(torch.LongTensor)\n",
    "        data,label=data.to(device),label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model_output,aux1,aux2=model(data)\n",
    "        loss=loss_fn(model_output,label)+0.3*(loss_fn(aux1,label)+loss_fn(aux2,label))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(batch_ids+1) % 50 ==0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch,batch_ids*len(data),len(train_loader.dataset),\n",
    "                100.*batch_ids/len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f29ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader,device):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for data,label in test_loader:\n",
    "            data,label=data.to(device),label.to(device)\n",
    "            y_hat=model(data)\n",
    "            test_loss+=F.nll_loss(y_hat,label,reduction='sum').item()\n",
    "            _,y_pred=torch.max(y_hat,1)\n",
    "            correct+=(y_pred==label).sum().item()\n",
    "            \n",
    "        test_loss/=len(test_dataset)\n",
    "        print(\"\\n Test Set: Average loss: {:.0f}, Accuracy:{}/{} ({:.0f}%)\".format(\n",
    "            test_loss,correct,len(test_dataset),100.*correct/len(test_dataset)))\n",
    "        print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdb3d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [12544/60000 (21%)]\tLoss: 3.549962\n",
      "Train Epoch: 1 [25344/60000 (42%)]\tLoss: 1.973874\n",
      "Train Epoch: 1 [38144/60000 (63%)]\tLoss: 1.402147\n",
      "Train Epoch: 1 [50944/60000 (85%)]\tLoss: 1.300418\n",
      "\n",
      " Test Set: Average loss: -7, Accuracy:7364/10000 (74%)\n",
      "==================================================\n",
      "Train Epoch: 2 [12544/60000 (21%)]\tLoss: 1.185213\n",
      "Train Epoch: 2 [25344/60000 (42%)]\tLoss: 1.094565\n",
      "Train Epoch: 2 [38144/60000 (63%)]\tLoss: 1.055251\n",
      "Train Epoch: 2 [50944/60000 (85%)]\tLoss: 1.047973\n",
      "\n",
      " Test Set: Average loss: -7, Accuracy:7829/10000 (78%)\n",
      "==================================================\n",
      "Train Epoch: 3 [12544/60000 (21%)]\tLoss: 0.891079\n",
      "Train Epoch: 3 [25344/60000 (42%)]\tLoss: 0.825268\n",
      "Train Epoch: 3 [38144/60000 (63%)]\tLoss: 0.910310\n",
      "Train Epoch: 3 [50944/60000 (85%)]\tLoss: 0.996392\n",
      "\n",
      " Test Set: Average loss: -8, Accuracy:8164/10000 (82%)\n",
      "==================================================\n",
      "Train Epoch: 4 [12544/60000 (21%)]\tLoss: 0.839998\n",
      "Train Epoch: 4 [25344/60000 (42%)]\tLoss: 0.738547\n",
      "Train Epoch: 4 [38144/60000 (63%)]\tLoss: 0.617730\n",
      "Train Epoch: 4 [50944/60000 (85%)]\tLoss: 0.839295\n",
      "\n",
      " Test Set: Average loss: -9, Accuracy:8343/10000 (83%)\n",
      "==================================================\n",
      "Train Epoch: 5 [12544/60000 (21%)]\tLoss: 0.858943\n",
      "Train Epoch: 5 [25344/60000 (42%)]\tLoss: 0.870472\n",
      "Train Epoch: 5 [38144/60000 (63%)]\tLoss: 0.657884\n",
      "Train Epoch: 5 [50944/60000 (85%)]\tLoss: 0.767863\n",
      "\n",
      " Test Set: Average loss: -9, Accuracy:8522/10000 (85%)\n",
      "==================================================\n",
      "Train Epoch: 6 [12544/60000 (21%)]\tLoss: 0.696567\n",
      "Train Epoch: 6 [25344/60000 (42%)]\tLoss: 0.661261\n",
      "Train Epoch: 6 [38144/60000 (63%)]\tLoss: 0.885694\n",
      "Train Epoch: 6 [50944/60000 (85%)]\tLoss: 0.586763\n",
      "\n",
      " Test Set: Average loss: -9, Accuracy:8605/10000 (86%)\n",
      "==================================================\n",
      "Train Epoch: 7 [12544/60000 (21%)]\tLoss: 0.469360\n",
      "Train Epoch: 7 [25344/60000 (42%)]\tLoss: 0.543406\n",
      "Train Epoch: 7 [38144/60000 (63%)]\tLoss: 0.569659\n",
      "Train Epoch: 7 [50944/60000 (85%)]\tLoss: 0.642962\n",
      "\n",
      " Test Set: Average loss: -10, Accuracy:8689/10000 (87%)\n",
      "==================================================\n",
      "Train Epoch: 8 [12544/60000 (21%)]\tLoss: 0.504054\n",
      "Train Epoch: 8 [25344/60000 (42%)]\tLoss: 0.509971\n",
      "Train Epoch: 8 [38144/60000 (63%)]\tLoss: 0.482034\n",
      "Train Epoch: 8 [50944/60000 (85%)]\tLoss: 0.555180\n",
      "\n",
      " Test Set: Average loss: -10, Accuracy:8779/10000 (88%)\n",
      "==================================================\n",
      "Train Epoch: 9 [12544/60000 (21%)]\tLoss: 0.564458\n",
      "Train Epoch: 9 [25344/60000 (42%)]\tLoss: 0.521349\n",
      "Train Epoch: 9 [38144/60000 (63%)]\tLoss: 0.502559\n",
      "Train Epoch: 9 [50944/60000 (85%)]\tLoss: 0.636722\n",
      "\n",
      " Test Set: Average loss: -10, Accuracy:8831/10000 (88%)\n",
      "==================================================\n",
      "Train Epoch: 10 [12544/60000 (21%)]\tLoss: 0.563213\n",
      "Train Epoch: 10 [25344/60000 (42%)]\tLoss: 0.592225\n",
      "Train Epoch: 10 [38144/60000 (63%)]\tLoss: 0.517048\n",
      "Train Epoch: 10 [50944/60000 (85%)]\tLoss: 0.563484\n",
      "\n",
      " Test Set: Average loss: -11, Accuracy:8873/10000 (89%)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    seed=42\n",
    "    EPOCHS=10\n",
    "    \n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        train(model,train_loader,optimizer,epoch,device)\n",
    "        test(model,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32e3db8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900ee59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearn] *",
   "language": "python",
   "name": "conda-env-deeplearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
