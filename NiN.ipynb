{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c2d257a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0a2bff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES=10\n",
    "\n",
    "class NiN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NiN,self).__init__()\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Conv2d(1,96,kernel_size=11,stride=4,padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96,96,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96,96,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3,stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "        \n",
    "            nn.Conv2d(96,256,kernel_size=5,stride=1,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Dropout(0.5),\n",
    "        \n",
    "            nn.Conv2d(256,384,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,384,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,384,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Conv2d(384,10,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(10,10,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(10,10,kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "                       \n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.classifier(x)\n",
    "        x=x.view(x.size(0),CLASSES)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "482b851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Conv2d(1, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        x = x.view(x.size(0), 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d48554e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES=10\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "76baf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_conf=transforms.Compose([transforms.Resize((224,224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.1307,),(0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8e6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ransform_conf=transforms.Compose([transforms.ToTensor()])\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc0635f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "train_dataset=datasets.FashionMNIST('/home/ubuntu/gpu_work/',train=True,download=True,transform=transform_conf)\n",
    "test_dataset=datasets.FashionMNIST('/home/ubuntu/gpu_work/',train=True,download=True,transform=transform_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5cb895de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "47ccdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NiN().to(device)\n",
    "#model=Net().to(device)\n",
    "optimizer=optim.Adam(params=model.parameters(),lr=0.0001)\n",
    "loss_fn=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "26e6a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,optimizer,device,epoch):\n",
    "    model.train()\n",
    "    for batch_ids, (data,classes) in enumerate(train_loader):\n",
    "        classes=classes.type(torch.LongTensor)\n",
    "        data,classes=data.to(device),classes.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=loss_fn(output,classes)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(batch_ids+1) % 500 == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "                epoch, batch_ids* len(data), len(train_loader.dataset),\n",
    "                100.*batch_ids / len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76ea0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader,device):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for data, classes in test_loader:\n",
    "            data, classes = data.to(device), classes.to(device)\n",
    "            y_hat=model(data)\n",
    "            _,y_pred=torch.max(y_hat,1)\n",
    "            correct+=(y_pred==classes).sum().item()\n",
    "            test_loss+=F.nll_loss(y_hat,classes,reduction='sum').item()\n",
    "        test_loss/=len(test_dataset)\n",
    "        print(\"\\n Test set: Avarage loss: {:.0f},Accuracy:{}/{} ({:.0f}%)\\n\".format(\n",
    "            test_loss,correct,len(test_dataset),100.*correct/len(test_dataset)))\n",
    "        print('='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "81c86d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [31936/60000 (53%)]\tLoss: 0.685712\n",
      "\n",
      " Test set: Avarage loss: -17,Accuracy:47438/60000 (79%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 2 [31936/60000 (53%)]\tLoss: 0.547450\n",
      "\n",
      " Test set: Avarage loss: -17,Accuracy:47948/60000 (80%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 3 [31936/60000 (53%)]\tLoss: 0.433725\n",
      "\n",
      " Test set: Avarage loss: -21,Accuracy:48892/60000 (81%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 4 [31936/60000 (53%)]\tLoss: 0.522983\n",
      "\n",
      " Test set: Avarage loss: -21,Accuracy:49819/60000 (83%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 5 [31936/60000 (53%)]\tLoss: 0.724332\n",
      "\n",
      " Test set: Avarage loss: -20,Accuracy:50247/60000 (84%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 6 [31936/60000 (53%)]\tLoss: 0.310877\n",
      "\n",
      " Test set: Avarage loss: -20,Accuracy:50280/60000 (84%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 7 [31936/60000 (53%)]\tLoss: 0.608101\n",
      "\n",
      " Test set: Avarage loss: -21,Accuracy:50780/60000 (85%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 8 [31936/60000 (53%)]\tLoss: 0.396246\n",
      "\n",
      " Test set: Avarage loss: -23,Accuracy:51275/60000 (85%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 9 [31936/60000 (53%)]\tLoss: 0.396898\n",
      "\n",
      " Test set: Avarage loss: -21,Accuracy:51435/60000 (86%)\n",
      "\n",
      "==============================\n",
      "Train Epoch: 10 [31936/60000 (53%)]\tLoss: 0.354767\n",
      "\n",
      " Test set: Avarage loss: -22,Accuracy:51489/60000 (86%)\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    seed=42\n",
    "    EPOCHS=10\n",
    "    \n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        train(model,train_loader,optimizer,device,epoch)\n",
    "        test(model,test_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd1bac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=torch.rand(64,10,50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "72e742fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8488b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(mat.size(0))\n",
    "temp=mat.view(64,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fcb84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=nn.Flatten()\n",
    "temp=fn(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78c4363d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 25000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "008f6fc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c69ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool of square window of size=3, stride=2\n",
    "#m = nn.AdaAvgPool2d(7, stride=3)\n",
    "# pool of non-square window\n",
    "m = nn.AdaptiveAvgPool2d((1, 1))\n",
    "input = torch.randn(1, 16, 80, 80)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e4e06950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b66964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearn] *",
   "language": "python",
   "name": "conda-env-deeplearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
